{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 12*4*4, out_features = 120)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 60)\n",
    "        self.out = nn.Linear(in_features = 60, out_features = 10)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        t = t.flatten(start_dim = 1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "      return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        \n",
    "        Run = namedtuple(\"Run\", params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "            \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "    \n",
    "    def begin_run(self, run, network, loader):\n",
    "        \n",
    "        self.run_start_time = time.time()\n",
    "        \n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment = f'-{run}')\n",
    "        \n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        #self.tb.add_image('images', grid)\n",
    "        #self.tb.add_graph(self.network, images)\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "        \n",
    "        \n",
    "       # zero epoch count, loss, accuracy, \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        \n",
    "    # \n",
    "    def end_epoch(self):\n",
    "        # calculate epoch duration and run duration(accumulate)\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        # record epoch loss and accuracy\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        # Record epoch loss and accuracy to TensorBoard \n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        # Record params to TensorBoard\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "    \n",
    "\n",
    "        # Write into 'results' (OrderedDict) for all run related data\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "\n",
    "        # Record hyper-params into 'results'\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "\n",
    "        # display epoch information and show progress\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "\n",
    "      # accumulate loss of batch into entire epoch loss\n",
    "    def track_loss(self, loss):\n",
    "        # multiply batch size so variety of batch sizes can be compared\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "      # accumulate number of corrects of batch into entire epoch num_correct\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, lables):\n",
    "        return preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "        self.run_data,\n",
    "        orient = \"columns\").to_csv(f'{fileName}.csv')\n",
    "        \n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "network1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    #flatten every image in the batch, but not the batch itself\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features = 12*4*4, out_features = 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features = 120, out_features = 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features = 60, out_features = 10)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "network2 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    # how many features coming in from the conv layer\n",
    "    # scale and shift parameters inside\n",
    "    nn.BatchNorm2d(6),\n",
    "    nn.Conv2d(in_channels = 6, out_channels = 12, kernel_size = 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "    nn.Flatten(start_dim = 1),\n",
    "    nn.Linear(in_features = 12*4*4, out_features = 120),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(120),\n",
    "    nn.Linear(in_features = 120, out_features = 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features = 60, out_features = 10)\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST'\n",
    "    ,train = True\n",
    "    ,download = True\n",
    "    ,transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size = len(train_set), num_workers = 1, pin_memory = True\n",
    ")\n",
    "data = next(iter(loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root = './data/FashionMNIST'\n",
    "    ,train = True\n",
    "    ,download = True\n",
    "    ,transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal': train_set,\n",
    "    'normal' : train_set_normal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple networks through testing framework\n",
    "networks = {\n",
    "    'no_batch_norm': network1,\n",
    "    'batch_norm': network2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830967</td>\n",
       "      <td>0.683533</td>\n",
       "      <td>10.145446</td>\n",
       "      <td>10.644288</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.826933</td>\n",
       "      <td>8.234865</td>\n",
       "      <td>19.074716</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.386308</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>8.262508</td>\n",
       "      <td>27.400810</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.351570</td>\n",
       "      <td>0.869650</td>\n",
       "      <td>8.278030</td>\n",
       "      <td>35.743322</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325868</td>\n",
       "      <td>0.879217</td>\n",
       "      <td>8.239512</td>\n",
       "      <td>44.045652</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.311092</td>\n",
       "      <td>0.886017</td>\n",
       "      <td>8.292844</td>\n",
       "      <td>52.400483</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.295289</td>\n",
       "      <td>0.890933</td>\n",
       "      <td>8.291497</td>\n",
       "      <td>60.753310</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.278343</td>\n",
       "      <td>0.897567</td>\n",
       "      <td>8.271598</td>\n",
       "      <td>69.090849</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.271311</td>\n",
       "      <td>0.900017</td>\n",
       "      <td>8.250522</td>\n",
       "      <td>77.402763</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.259443</td>\n",
       "      <td>0.904267</td>\n",
       "      <td>8.278640</td>\n",
       "      <td>85.748942</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.252217</td>\n",
       "      <td>0.905633</td>\n",
       "      <td>8.238525</td>\n",
       "      <td>94.061135</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.244858</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>8.270107</td>\n",
       "      <td>102.399400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.243074</td>\n",
       "      <td>0.908583</td>\n",
       "      <td>8.231991</td>\n",
       "      <td>110.699174</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.238660</td>\n",
       "      <td>0.910033</td>\n",
       "      <td>8.265609</td>\n",
       "      <td>119.039309</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.240665</td>\n",
       "      <td>0.909817</td>\n",
       "      <td>8.273778</td>\n",
       "      <td>127.381114</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.238488</td>\n",
       "      <td>0.910067</td>\n",
       "      <td>8.346221</td>\n",
       "      <td>135.796802</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.231208</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>8.267430</td>\n",
       "      <td>144.139536</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.225647</td>\n",
       "      <td>0.914267</td>\n",
       "      <td>8.267353</td>\n",
       "      <td>152.481856</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.222186</td>\n",
       "      <td>0.914483</td>\n",
       "      <td>8.276869</td>\n",
       "      <td>160.822687</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.217743</td>\n",
       "      <td>0.916633</td>\n",
       "      <td>8.241832</td>\n",
       "      <td>169.131666</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585166</td>\n",
       "      <td>0.786867</td>\n",
       "      <td>8.264635</td>\n",
       "      <td>8.614547</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342878</td>\n",
       "      <td>0.873117</td>\n",
       "      <td>8.306749</td>\n",
       "      <td>17.008978</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.303684</td>\n",
       "      <td>0.886733</td>\n",
       "      <td>8.220021</td>\n",
       "      <td>25.316944</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280749</td>\n",
       "      <td>0.896067</td>\n",
       "      <td>8.308954</td>\n",
       "      <td>33.705618</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.261276</td>\n",
       "      <td>0.903050</td>\n",
       "      <td>8.240916</td>\n",
       "      <td>42.027641</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.249681</td>\n",
       "      <td>0.906517</td>\n",
       "      <td>8.333558</td>\n",
       "      <td>50.446272</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.238549</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>8.276702</td>\n",
       "      <td>58.806390</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.229057</td>\n",
       "      <td>0.913567</td>\n",
       "      <td>8.286002</td>\n",
       "      <td>67.180985</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.220264</td>\n",
       "      <td>0.916833</td>\n",
       "      <td>8.300925</td>\n",
       "      <td>75.561898</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.213956</td>\n",
       "      <td>0.919367</td>\n",
       "      <td>8.276422</td>\n",
       "      <td>83.924337</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.206537</td>\n",
       "      <td>0.921900</td>\n",
       "      <td>8.315146</td>\n",
       "      <td>92.315603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0.925683</td>\n",
       "      <td>8.354903</td>\n",
       "      <td>100.762196</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>0.926850</td>\n",
       "      <td>8.291974</td>\n",
       "      <td>109.131425</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.192696</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>8.298658</td>\n",
       "      <td>117.507253</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.190935</td>\n",
       "      <td>0.927650</td>\n",
       "      <td>8.430041</td>\n",
       "      <td>126.022603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.187565</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>8.299871</td>\n",
       "      <td>134.400142</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.932233</td>\n",
       "      <td>8.354341</td>\n",
       "      <td>142.847733</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.178035</td>\n",
       "      <td>0.932050</td>\n",
       "      <td>8.299305</td>\n",
       "      <td>151.231940</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.172256</td>\n",
       "      <td>0.933733</td>\n",
       "      <td>8.276240</td>\n",
       "      <td>159.596072</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.167080</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>8.387012</td>\n",
       "      <td>168.065338</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  0.830967  0.683533       10.145446     10.644288  0.01   \n",
       "1     1      2  0.455314  0.826933        8.234865     19.074716  0.01   \n",
       "2     1      3  0.386308  0.856200        8.262508     27.400810  0.01   \n",
       "3     1      4  0.351570  0.869650        8.278030     35.743322  0.01   \n",
       "4     1      5  0.325868  0.879217        8.239512     44.045652  0.01   \n",
       "5     1      6  0.311092  0.886017        8.292844     52.400483  0.01   \n",
       "6     1      7  0.295289  0.890933        8.291497     60.753310  0.01   \n",
       "7     1      8  0.278343  0.897567        8.271598     69.090849  0.01   \n",
       "8     1      9  0.271311  0.900017        8.250522     77.402763  0.01   \n",
       "9     1     10  0.259443  0.904267        8.278640     85.748942  0.01   \n",
       "10    1     11  0.252217  0.905633        8.238525     94.061135  0.01   \n",
       "11    1     12  0.244858  0.909000        8.270107    102.399400  0.01   \n",
       "12    1     13  0.243074  0.908583        8.231991    110.699174  0.01   \n",
       "13    1     14  0.238660  0.910033        8.265609    119.039309  0.01   \n",
       "14    1     15  0.240665  0.909817        8.273778    127.381114  0.01   \n",
       "15    1     16  0.238488  0.910067        8.346221    135.796802  0.01   \n",
       "16    1     17  0.231208  0.912900        8.267430    144.139536  0.01   \n",
       "17    1     18  0.225647  0.914267        8.267353    152.481856  0.01   \n",
       "18    1     19  0.222186  0.914483        8.276869    160.822687  0.01   \n",
       "19    1     20  0.217743  0.916633        8.241832    169.131666  0.01   \n",
       "20    2      1  0.585166  0.786867        8.264635      8.614547  0.01   \n",
       "21    2      2  0.342878  0.873117        8.306749     17.008978  0.01   \n",
       "22    2      3  0.303684  0.886733        8.220021     25.316944  0.01   \n",
       "23    2      4  0.280749  0.896067        8.308954     33.705618  0.01   \n",
       "24    2      5  0.261276  0.903050        8.240916     42.027641  0.01   \n",
       "25    2      6  0.249681  0.906517        8.333558     50.446272  0.01   \n",
       "26    2      7  0.238549  0.910750        8.276702     58.806390  0.01   \n",
       "27    2      8  0.229057  0.913567        8.286002     67.180985  0.01   \n",
       "28    2      9  0.220264  0.916833        8.300925     75.561898  0.01   \n",
       "29    2     10  0.213956  0.919367        8.276422     83.924337  0.01   \n",
       "30    2     11  0.206537  0.921900        8.315146     92.315603  0.01   \n",
       "31    2     12  0.199013  0.925683        8.354903    100.762196  0.01   \n",
       "32    2     13  0.195068  0.926850        8.291974    109.131425  0.01   \n",
       "33    2     14  0.192696  0.926500        8.298658    117.507253  0.01   \n",
       "34    2     15  0.190935  0.927650        8.430041    126.022603  0.01   \n",
       "35    2     16  0.187565  0.928000        8.299871    134.400142  0.01   \n",
       "36    2     17  0.179296  0.932233        8.354341    142.847733  0.01   \n",
       "37    2     18  0.178035  0.932050        8.299305    151.231940  0.01   \n",
       "38    2     19  0.172256  0.933733        8.276240    159.596072  0.01   \n",
       "39    2     20  0.167080  0.936717        8.387012    168.065338  0.01   \n",
       "\n",
       "    batch_size  num_workers device trainset        network  \n",
       "0         1000            1   cuda   normal  no_batch_norm  \n",
       "1         1000            1   cuda   normal  no_batch_norm  \n",
       "2         1000            1   cuda   normal  no_batch_norm  \n",
       "3         1000            1   cuda   normal  no_batch_norm  \n",
       "4         1000            1   cuda   normal  no_batch_norm  \n",
       "5         1000            1   cuda   normal  no_batch_norm  \n",
       "6         1000            1   cuda   normal  no_batch_norm  \n",
       "7         1000            1   cuda   normal  no_batch_norm  \n",
       "8         1000            1   cuda   normal  no_batch_norm  \n",
       "9         1000            1   cuda   normal  no_batch_norm  \n",
       "10        1000            1   cuda   normal  no_batch_norm  \n",
       "11        1000            1   cuda   normal  no_batch_norm  \n",
       "12        1000            1   cuda   normal  no_batch_norm  \n",
       "13        1000            1   cuda   normal  no_batch_norm  \n",
       "14        1000            1   cuda   normal  no_batch_norm  \n",
       "15        1000            1   cuda   normal  no_batch_norm  \n",
       "16        1000            1   cuda   normal  no_batch_norm  \n",
       "17        1000            1   cuda   normal  no_batch_norm  \n",
       "18        1000            1   cuda   normal  no_batch_norm  \n",
       "19        1000            1   cuda   normal  no_batch_norm  \n",
       "20        1000            1   cuda   normal     batch_norm  \n",
       "21        1000            1   cuda   normal     batch_norm  \n",
       "22        1000            1   cuda   normal     batch_norm  \n",
       "23        1000            1   cuda   normal     batch_norm  \n",
       "24        1000            1   cuda   normal     batch_norm  \n",
       "25        1000            1   cuda   normal     batch_norm  \n",
       "26        1000            1   cuda   normal     batch_norm  \n",
       "27        1000            1   cuda   normal     batch_norm  \n",
       "28        1000            1   cuda   normal     batch_norm  \n",
       "29        1000            1   cuda   normal     batch_norm  \n",
       "30        1000            1   cuda   normal     batch_norm  \n",
       "31        1000            1   cuda   normal     batch_norm  \n",
       "32        1000            1   cuda   normal     batch_norm  \n",
       "33        1000            1   cuda   normal     batch_norm  \n",
       "34        1000            1   cuda   normal     batch_norm  \n",
       "35        1000            1   cuda   normal     batch_norm  \n",
       "36        1000            1   cuda   normal     batch_norm  \n",
       "37        1000            1   cuda   normal     batch_norm  \n",
       "38        1000            1   cuda   normal     batch_norm  \n",
       "39        1000            1   cuda   normal     batch_norm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test different configurations\n",
    "# for every run [value] that is going to be used e.g [.001, .01] = two runs\n",
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000],\n",
    "    num_workers = [1],\n",
    "    device = [\"cuda\"],\n",
    "    trainset = [\"normal\"],\n",
    "    # try all the values in the dict network1, network2\n",
    "    network = list(networks.keys())\n",
    ")\n",
    "m = RunManager()\n",
    "# active run or current run\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    \n",
    "    device = torch.device(run.device)\n",
    "    # redefine the network\n",
    "    network = networks[run.network].to(device)\n",
    "    loader = DataLoader(trainsets[run.trainset], batch_size = run.batch_size, num_workers = run.num_workers, \n",
    "                       pin_memory = True) \n",
    "    optimizer = optim.Adam(network.parameters(), lr = run.lr) \n",
    "    \n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(20):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            \n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "            #7.9\n",
    "            #optimizer.zero_grad()\n",
    "            #8 sec\n",
    "            for p in network.parameters(): p.grad = None\n",
    "            loss.backward() # Calculate gradients\n",
    "            optimizer.step() # Update Weights\n",
    "            \n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.167080</td>\n",
       "      <td>0.936717</td>\n",
       "      <td>8.387012</td>\n",
       "      <td>168.065338</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.172256</td>\n",
       "      <td>0.933733</td>\n",
       "      <td>8.276240</td>\n",
       "      <td>159.596072</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.932233</td>\n",
       "      <td>8.354341</td>\n",
       "      <td>142.847733</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.178035</td>\n",
       "      <td>0.932050</td>\n",
       "      <td>8.299305</td>\n",
       "      <td>151.231940</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.187565</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>8.299871</td>\n",
       "      <td>134.400142</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.190935</td>\n",
       "      <td>0.927650</td>\n",
       "      <td>8.430041</td>\n",
       "      <td>126.022603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.195068</td>\n",
       "      <td>0.926850</td>\n",
       "      <td>8.291974</td>\n",
       "      <td>109.131425</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.192696</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>8.298658</td>\n",
       "      <td>117.507253</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0.925683</td>\n",
       "      <td>8.354903</td>\n",
       "      <td>100.762196</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.206537</td>\n",
       "      <td>0.921900</td>\n",
       "      <td>8.315146</td>\n",
       "      <td>92.315603</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.213956</td>\n",
       "      <td>0.919367</td>\n",
       "      <td>8.276422</td>\n",
       "      <td>83.924337</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.220264</td>\n",
       "      <td>0.916833</td>\n",
       "      <td>8.300925</td>\n",
       "      <td>75.561898</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.217743</td>\n",
       "      <td>0.916633</td>\n",
       "      <td>8.241832</td>\n",
       "      <td>169.131666</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.222186</td>\n",
       "      <td>0.914483</td>\n",
       "      <td>8.276869</td>\n",
       "      <td>160.822687</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.225647</td>\n",
       "      <td>0.914267</td>\n",
       "      <td>8.267353</td>\n",
       "      <td>152.481856</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.229057</td>\n",
       "      <td>0.913567</td>\n",
       "      <td>8.286002</td>\n",
       "      <td>67.180985</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.231208</td>\n",
       "      <td>0.912900</td>\n",
       "      <td>8.267430</td>\n",
       "      <td>144.139536</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.238549</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>8.276702</td>\n",
       "      <td>58.806390</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.238488</td>\n",
       "      <td>0.910067</td>\n",
       "      <td>8.346221</td>\n",
       "      <td>135.796802</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.238660</td>\n",
       "      <td>0.910033</td>\n",
       "      <td>8.265609</td>\n",
       "      <td>119.039309</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.240665</td>\n",
       "      <td>0.909817</td>\n",
       "      <td>8.273778</td>\n",
       "      <td>127.381114</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.244858</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>8.270107</td>\n",
       "      <td>102.399400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.243074</td>\n",
       "      <td>0.908583</td>\n",
       "      <td>8.231991</td>\n",
       "      <td>110.699174</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.249681</td>\n",
       "      <td>0.906517</td>\n",
       "      <td>8.333558</td>\n",
       "      <td>50.446272</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.252217</td>\n",
       "      <td>0.905633</td>\n",
       "      <td>8.238525</td>\n",
       "      <td>94.061135</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.259443</td>\n",
       "      <td>0.904267</td>\n",
       "      <td>8.278640</td>\n",
       "      <td>85.748942</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.261276</td>\n",
       "      <td>0.903050</td>\n",
       "      <td>8.240916</td>\n",
       "      <td>42.027641</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.271311</td>\n",
       "      <td>0.900017</td>\n",
       "      <td>8.250522</td>\n",
       "      <td>77.402763</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.278343</td>\n",
       "      <td>0.897567</td>\n",
       "      <td>8.271598</td>\n",
       "      <td>69.090849</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.280749</td>\n",
       "      <td>0.896067</td>\n",
       "      <td>8.308954</td>\n",
       "      <td>33.705618</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.295289</td>\n",
       "      <td>0.890933</td>\n",
       "      <td>8.291497</td>\n",
       "      <td>60.753310</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.303684</td>\n",
       "      <td>0.886733</td>\n",
       "      <td>8.220021</td>\n",
       "      <td>25.316944</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.311092</td>\n",
       "      <td>0.886017</td>\n",
       "      <td>8.292844</td>\n",
       "      <td>52.400483</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.325868</td>\n",
       "      <td>0.879217</td>\n",
       "      <td>8.239512</td>\n",
       "      <td>44.045652</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342878</td>\n",
       "      <td>0.873117</td>\n",
       "      <td>8.306749</td>\n",
       "      <td>17.008978</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.351570</td>\n",
       "      <td>0.869650</td>\n",
       "      <td>8.278030</td>\n",
       "      <td>35.743322</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.386308</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>8.262508</td>\n",
       "      <td>27.400810</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.455314</td>\n",
       "      <td>0.826933</td>\n",
       "      <td>8.234865</td>\n",
       "      <td>19.074716</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585166</td>\n",
       "      <td>0.786867</td>\n",
       "      <td>8.264635</td>\n",
       "      <td>8.614547</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>batch_norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830967</td>\n",
       "      <td>0.683533</td>\n",
       "      <td>10.145446</td>\n",
       "      <td>10.644288</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cuda</td>\n",
       "      <td>normal</td>\n",
       "      <td>no_batch_norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "39    2     20  0.167080  0.936717        8.387012    168.065338  0.01   \n",
       "38    2     19  0.172256  0.933733        8.276240    159.596072  0.01   \n",
       "36    2     17  0.179296  0.932233        8.354341    142.847733  0.01   \n",
       "37    2     18  0.178035  0.932050        8.299305    151.231940  0.01   \n",
       "35    2     16  0.187565  0.928000        8.299871    134.400142  0.01   \n",
       "34    2     15  0.190935  0.927650        8.430041    126.022603  0.01   \n",
       "32    2     13  0.195068  0.926850        8.291974    109.131425  0.01   \n",
       "33    2     14  0.192696  0.926500        8.298658    117.507253  0.01   \n",
       "31    2     12  0.199013  0.925683        8.354903    100.762196  0.01   \n",
       "30    2     11  0.206537  0.921900        8.315146     92.315603  0.01   \n",
       "29    2     10  0.213956  0.919367        8.276422     83.924337  0.01   \n",
       "28    2      9  0.220264  0.916833        8.300925     75.561898  0.01   \n",
       "19    1     20  0.217743  0.916633        8.241832    169.131666  0.01   \n",
       "18    1     19  0.222186  0.914483        8.276869    160.822687  0.01   \n",
       "17    1     18  0.225647  0.914267        8.267353    152.481856  0.01   \n",
       "27    2      8  0.229057  0.913567        8.286002     67.180985  0.01   \n",
       "16    1     17  0.231208  0.912900        8.267430    144.139536  0.01   \n",
       "26    2      7  0.238549  0.910750        8.276702     58.806390  0.01   \n",
       "15    1     16  0.238488  0.910067        8.346221    135.796802  0.01   \n",
       "13    1     14  0.238660  0.910033        8.265609    119.039309  0.01   \n",
       "14    1     15  0.240665  0.909817        8.273778    127.381114  0.01   \n",
       "11    1     12  0.244858  0.909000        8.270107    102.399400  0.01   \n",
       "12    1     13  0.243074  0.908583        8.231991    110.699174  0.01   \n",
       "25    2      6  0.249681  0.906517        8.333558     50.446272  0.01   \n",
       "10    1     11  0.252217  0.905633        8.238525     94.061135  0.01   \n",
       "9     1     10  0.259443  0.904267        8.278640     85.748942  0.01   \n",
       "24    2      5  0.261276  0.903050        8.240916     42.027641  0.01   \n",
       "8     1      9  0.271311  0.900017        8.250522     77.402763  0.01   \n",
       "7     1      8  0.278343  0.897567        8.271598     69.090849  0.01   \n",
       "23    2      4  0.280749  0.896067        8.308954     33.705618  0.01   \n",
       "6     1      7  0.295289  0.890933        8.291497     60.753310  0.01   \n",
       "22    2      3  0.303684  0.886733        8.220021     25.316944  0.01   \n",
       "5     1      6  0.311092  0.886017        8.292844     52.400483  0.01   \n",
       "4     1      5  0.325868  0.879217        8.239512     44.045652  0.01   \n",
       "21    2      2  0.342878  0.873117        8.306749     17.008978  0.01   \n",
       "3     1      4  0.351570  0.869650        8.278030     35.743322  0.01   \n",
       "2     1      3  0.386308  0.856200        8.262508     27.400810  0.01   \n",
       "1     1      2  0.455314  0.826933        8.234865     19.074716  0.01   \n",
       "20    2      1  0.585166  0.786867        8.264635      8.614547  0.01   \n",
       "0     1      1  0.830967  0.683533       10.145446     10.644288  0.01   \n",
       "\n",
       "    batch_size  num_workers device trainset        network  \n",
       "39        1000            1   cuda   normal     batch_norm  \n",
       "38        1000            1   cuda   normal     batch_norm  \n",
       "36        1000            1   cuda   normal     batch_norm  \n",
       "37        1000            1   cuda   normal     batch_norm  \n",
       "35        1000            1   cuda   normal     batch_norm  \n",
       "34        1000            1   cuda   normal     batch_norm  \n",
       "32        1000            1   cuda   normal     batch_norm  \n",
       "33        1000            1   cuda   normal     batch_norm  \n",
       "31        1000            1   cuda   normal     batch_norm  \n",
       "30        1000            1   cuda   normal     batch_norm  \n",
       "29        1000            1   cuda   normal     batch_norm  \n",
       "28        1000            1   cuda   normal     batch_norm  \n",
       "19        1000            1   cuda   normal  no_batch_norm  \n",
       "18        1000            1   cuda   normal  no_batch_norm  \n",
       "17        1000            1   cuda   normal  no_batch_norm  \n",
       "27        1000            1   cuda   normal     batch_norm  \n",
       "16        1000            1   cuda   normal  no_batch_norm  \n",
       "26        1000            1   cuda   normal     batch_norm  \n",
       "15        1000            1   cuda   normal  no_batch_norm  \n",
       "13        1000            1   cuda   normal  no_batch_norm  \n",
       "14        1000            1   cuda   normal  no_batch_norm  \n",
       "11        1000            1   cuda   normal  no_batch_norm  \n",
       "12        1000            1   cuda   normal  no_batch_norm  \n",
       "25        1000            1   cuda   normal     batch_norm  \n",
       "10        1000            1   cuda   normal  no_batch_norm  \n",
       "9         1000            1   cuda   normal  no_batch_norm  \n",
       "24        1000            1   cuda   normal     batch_norm  \n",
       "8         1000            1   cuda   normal  no_batch_norm  \n",
       "7         1000            1   cuda   normal  no_batch_norm  \n",
       "23        1000            1   cuda   normal     batch_norm  \n",
       "6         1000            1   cuda   normal  no_batch_norm  \n",
       "22        1000            1   cuda   normal     batch_norm  \n",
       "5         1000            1   cuda   normal  no_batch_norm  \n",
       "4         1000            1   cuda   normal  no_batch_norm  \n",
       "21        1000            1   cuda   normal     batch_norm  \n",
       "3         1000            1   cuda   normal  no_batch_norm  \n",
       "2         1000            1   cuda   normal  no_batch_norm  \n",
       "1         1000            1   cuda   normal  no_batch_norm  \n",
       "20        1000            1   cuda   normal     batch_norm  \n",
       "0         1000            1   cuda   normal  no_batch_norm  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(m.run_data).sort_values(\"accuracy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
